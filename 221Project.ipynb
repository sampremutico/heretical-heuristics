{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://blog.dataiku.com/2016/10/08/machine-learning-markov-chains-generate-clinton-trump-quotes\n",
    "#TODO: get a lot more text for each author, \n",
    "#implement starting a phrase with a <sentence begin> and ending it with a <sentence end>\n",
    "#implement Backoff, \n",
    "#implement word weights (right now the ngram densities are too low for weights to do much) for overall and in-dialogue\n",
    "#graph search\n",
    "#A state is the N words at the end of the sentence, and the list of magic words. A transition between states is the adding of a new word to the end of res. \n",
    "#Ngrams alg defines neighbors\n",
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 3\n",
    "MAX_DIALOGUE_LEN = 35\n",
    "AUTHOR_AUG = \"Augustine\"\n",
    "AUTHOR_ZZ = \"Zhuangzi\"\n",
    "MAGIC_WORDS = set([])#[\"god\",\"man\",\"world\",\"death\",\"heaven\",\"life\",\"time\",\"body\",\"mind\"])\n",
    "grams1 = {}\n",
    "grams2 = {}\n",
    "grams3 = {}\n",
    "empty_words = ['.',',',':','i','the','should','it','did','for','by','this','they','them','because','so','is','and','a','with','to','\\'', '\\\"','be','not','no','thus','in','have','as','but','from','on','do','at','or','an','will','my','so','if', 'these', 'those','of','was','there','then','what','we','its','it\\'s', 'as','into','that','may','are','he','can','how','such','were','which','\\'','who','him','any','one','his','like','about','when','has','things','yet','all','said']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class gramlib(object):\n",
    "    def __init__(self, gdict = [], start_list = []):\n",
    "        self.gdict = gdict\n",
    "        self.startList = start_list\n",
    "    def getPost(self,pre):\n",
    "        return self.gdict[pre]\n",
    "    def getStarter(self):\n",
    "        return random.choice(self.startList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_grams(grams, textfile): #initialize the dicts that store the markov probabilities for N-word chains\n",
    "    f = open(textfile)\n",
    "    s = f.read().replace('(','').replace(')','')\n",
    "    t = nltk.word_tokenize(s)\n",
    "    start_list = []\n",
    "    for i in range(len(t)-(N)):\n",
    "        trigram = tuple(t[x].lower() for x in range(i,i+N))\n",
    "        if(t[i-1]==\".\" or t[i-1]==\"!\" or t[i-1]==\"?\"):\n",
    "            if(t[i]!=\" \" and t[i]!=\",\" and t[i]!=\"\\'\" and t[i]!=\".\"):\n",
    "                start_list.append(trigram)\n",
    "        if trigram in grams.keys():\n",
    "            grams[trigram].add(t[i+N].lower())\n",
    "        else:\n",
    "            grams[trigram] = set([t[i+N].lower()])\n",
    "    g = gramlib(grams, start_list)\n",
    "    return g\n",
    "\n",
    "            \n",
    "def ngram_generate(grams): #generate text from a dict passed in\n",
    "    nwords = 0\n",
    "    start = grams.getStarter()\n",
    "    res = list(start)\n",
    "    while(nwords < 100):\n",
    "        pre = tuple(res[(-1*N):])\n",
    "        nextword = random.choice(list(grams[pre]))\n",
    "        res.append(nextword)\n",
    "        if nextword == '.' or nextword =='?': break\n",
    "        nwords +=1\n",
    "    if nwords ==100: res.append('-')\n",
    "    return \" \".join(res).replace(' .', '.').replace(' ,', ',').replace(' ;',';').replace(' ?', '?').replace(' \\'', '\\'').replace(' !', '!')\n",
    "\n",
    "def solve_density(grams): #On average, how many words are in the dict for each ngram?\n",
    "    total = 0.0\n",
    "    div = 0\n",
    "    for word in grams.keys():\n",
    "        if(len(grams[word])>1):\n",
    "            total += len(grams[word])\n",
    "            div +=1\n",
    "    return total/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize_grams(grams1, 'augustine_full.txt')\n",
    "#initialize_grams(grams1, 'zhuangzi.txt')\n",
    "#solve_density(grams1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramSearchProblem(object):\n",
    "    def __init__(self, N, grams, magic_words):\n",
    "        self.N = N\n",
    "        self.grams = grams\n",
    "        self.magic_words = magic_words\n",
    "        self.startActions = None\n",
    "\n",
    "    # Trivially return 100 if word is magic word, 1 otherwise\n",
    "    def ngram_cost(self,state):\n",
    "        if state[-1] in self.magic_words:\n",
    "            return 30#try different weights\n",
    "        if state[-1] == \".\" or state[-1] == \"?\" or state[-1] == \"!\":\n",
    "            return 5\n",
    "        return 1\n",
    "    \n",
    "    def ngram_generate_next_words(self, curr_gram):\n",
    "        pre = tuple(curr_gram[(-1*N):])\n",
    "        l =self.grams.getPost(pre)\n",
    "        pres = []\n",
    "        for i in range(len(curr_gram)-N):\n",
    "            pres.append(curr_gram[i:i+N])\n",
    "        suffix = curr_gram[-1*(N-1):]\n",
    "        result = [w for w in l if suffix+[w] not in pres]\n",
    "        final_result = [p for p in result if curr_gram.count(p)<2]\n",
    "        return final_result\n",
    "       # print(\"pres >>>>\", pres)\n",
    "        #print(\"res >>>>>\", result)\n",
    "        #if (len(result)!=len(l)):\n",
    "         #   print('success')\n",
    "        return result\n",
    "    \n",
    "    def startState(self):\n",
    "        start = self.grams.getStarter()\n",
    "        self.startActions = list(start)\n",
    "        return list(start)\n",
    "\n",
    "    def isEnd(self, state):\n",
    "        return len(state) >= MAX_DIALOGUE_LEN or state[-1][-1] == \".\" or state[-1][-1] == \"?\" or state[-1][-1] == \"!\"#max blurb length or last word ends in period\n",
    "    \n",
    "    def succAndCost(self, state):\n",
    "        result = []\n",
    "        possible_next_words = self.ngram_generate_next_words(state)\n",
    "        for next_word in possible_next_words:\n",
    "            next_state = state[:]+[next_word]\n",
    "            result.append((next_word, next_state, self.ngram_cost(next_state)))\n",
    "        return result\n",
    "    def getMagic(self):\n",
    "        return self.magic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backtrackingSearch(problem):\n",
    "    bestTotalCost = [float('-inf')]\n",
    "    bestHistory = [None]\n",
    "    def recurse(state,curr_history,curr_cost):\n",
    "        if problem.isEnd(state):\n",
    "            if curr_cost > bestTotalCost[0]:\n",
    "                bestTotalCost[0], bestHistory[0] = curr_cost, curr_history \n",
    "            return\n",
    "        for action, next_state, cost in problem.succAndCost(state):\n",
    "            recurse(next_state, curr_history+[action], curr_cost+cost)\n",
    "    \n",
    "    recurse(problem.startState(),problem.startState(),0)\n",
    "    bestHistory = procStr(\" \".join(bestHistory[0]))\n",
    "   # print(\"<-----------Best History--------->\")\n",
    "    #print(bestHistory)return \n",
    "    #print(\"<--------------Score------------->\")\n",
    "    #print(bestTotalCost[0])\n",
    "    return bestHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kBeamsSearch(problem,k = 2500):\n",
    "    C = []\n",
    "    for i in range(k):\n",
    "        s = problem.startState()\n",
    "        i = 0\n",
    "        for w in problem.getMagic():\n",
    "            if w in s:\n",
    "                i += 30\n",
    "        C.append((s,s,i))\n",
    "    complete_beams = []\n",
    "    while len(complete_beams) < k:\n",
    "        for j in range(len(C)):\n",
    "            curr_beam = C[j][:]\n",
    "            for action, next_state, cost in problem.succAndCost(curr_beam[0]):    \n",
    "                C.append((next_state, curr_beam[1]+[action],curr_beam[2]+cost))\n",
    "        C = sorted(C, key=lambda x: x[2])[::-1]\n",
    "        C = C if len(C) < k else C[:k]\n",
    "        for beam in C:\n",
    "            if problem.isEnd(beam[0]):\n",
    "                complete_beams.append(beam)  \n",
    "        new_beams = [b for b in C if b not in complete_beams]\n",
    "        C = new_beams\n",
    "    res = complete_beams[-1]\n",
    "    return procStr(\" \".join(res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#blurb = backtrackingSearch(NGramSearchProblem(N,grams1,MAGIC_WORDS)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'procStr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fd2483738620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'zhuangzi.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_grams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrams1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspeech1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkBeamsSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNGramSearchProblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAGIC_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mspeech1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-dd61044ca1a3>\u001b[0m in \u001b[0;36mkBeamsSearch\u001b[0;34m(problem, k)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_beams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_beams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'procStr' is not defined"
     ]
    }
   ],
   "source": [
    "sigs = []\n",
    "text1 = 'zhuangzi.txt'\n",
    "g1 = initialize_grams(grams1, text1)\n",
    "speech1 = kBeamsSearch(NGramSearchProblem(N,g1,set(list(MAGIC_WORDS)+sigs)))\n",
    "speech1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#todo - get rid of bad punctuation\n",
    "#capitalize first letter\n",
    "#end with a hyphen if they are cut off.\n",
    "def convo(text1, text2, author1, author2):\n",
    "    grams1 = {}\n",
    "    grams2 = {}\n",
    "    g1 = initialize_grams(grams1, text1)\n",
    "    g2 = initialize_grams(grams2, text2)\n",
    "    print('first ngram density: '+ str(solve_density(grams1))+ '\\n')\n",
    "    print('second ngram density: '+ str(solve_density(grams2))+ '\\n')\n",
    "    sigs = []\n",
    "    for i in range(5):\n",
    "        print(author1 + ':')\n",
    "        #speech1 = ngram_generate(grams1)\n",
    "        #speech1 = backtrackingSearch(NGramSearchProblem(N,g1,set(list(MAGIC_WORDS)+sigs)))\n",
    "        speech1 = kBeamsSearch(NGramSearchProblem(N,g1,set(list(MAGIC_WORDS)+sigs)))\n",
    "        sigs = getSigWords(speech1)\n",
    "        print(speech1)\n",
    "        print('\\n')\n",
    "        #print(sigs)\n",
    "        print('\\n')\n",
    "        #speech2 = ngram_generate(grams2)\n",
    "        #speech2 = backtrackingSearch(NGramSearchProblem(N,g2,set(list(MAGIC_WORDS)+sigs)))\n",
    "        speech2 = kBeamsSearch(NGramSearchProblem(N,g2,set(list(MAGIC_WORDS)+sigs)))\n",
    "        sigs = getSigWords(speech2)\n",
    "        print(author2 + ':')\n",
    "        print(speech2)\n",
    "        print('\\n')\n",
    "        #print(sigs)\n",
    "        print('\\n')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first ngram density: 2.954440026507621\n",
      "\n",
      "second ngram density: 3.4217966453397892\n",
      "\n",
      "Zhuangzi:\n",
      "Zi-chan said to him, do not know who it is that you will not be angry with it.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-676acf3e6d9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zhuangzi.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'augustine_full.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Zhuangzi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Augustine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-23ca19a7b4bc>\u001b[0m in \u001b[0;36mconvo\u001b[0;34m(text1, text2, author1, author2)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#speech2 = ngram_generate(grams2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#speech2 = backtrackingSearch(NGramSearchProblem(N,g2,set(list(MAGIC_WORDS)+sigs)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mspeech2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkBeamsSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNGramSearchProblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAGIC_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0msigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSigWords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dd61044ca1a3>\u001b[0m in \u001b[0;36mkBeamsSearch\u001b[0;34m(problem, k)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccAndCost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_beam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_beam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurr_beam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbeam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dd61044ca1a3>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccAndCost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_beam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_beam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurr_beam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbeam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convo('zhuangzi.txt','augustine_full.txt', 'Zhuangzi','Augustine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSigWords(str):\n",
    "    s = set(nltk.word_tokenize(str))\n",
    "    for w in empty_words:\n",
    "        if w in s: s.remove(w)\n",
    "    return list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def procStr(str):\n",
    "    newstr = str.replace('0','').replace('1','').replace('2','').replace('3','').replace('4','').replace('5','').replace('6','').replace('7','').replace('8','').replace('9','').replace('`','').replace('\\'','').replace(' .', '.').replace(' ,', ',').replace(' ;',';').replace(' ?', '?').replace(' \\'', '\\'').replace(' !', '!').replace(' i ', ' I ').replace(' i ', ' I ').replace(' ;',';')\n",
    "    if (newstr[-1]!='.' and newstr[-1]!='?' and newstr[-1]!='!'):\n",
    "        newstr = newstr[:] + '-'\n",
    "    return newstr[0].upper() + newstr[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def triple_conv(text1,text2,text3,author1,author2,author3,length):\n",
    "    grams1 = {}\n",
    "    grams2 = {}\n",
    "    grams3 = {}\n",
    "    g1 = initialize_grams(grams1, text1)\n",
    "    g2 = initialize_grams(grams2, text2)\n",
    "    g3 = initialize_grams(grams3, text3)\n",
    "    print('first ngram density_v2: '+ str(solve_density(grams1))+ '\\n')\n",
    "    print('second ngram density_v2: '+ str(solve_density(grams2))+ '\\n')\n",
    "    print('third ngram density_v2: '+ str(solve_density(grams3))+ '\\n')\n",
    "    sigs = []\n",
    "    for i in range(length):\n",
    "        print(author1 + ':')\n",
    "        #speech1 = ngram_generate(grams1)\n",
    "        speech1 = kBeamsSearch(NGramSearchProblem(N,g1,set(list(MAGIC_WORDS)+sigs)))\n",
    "        sigs = getSigWords(speech1)\n",
    "        print(speech1)\n",
    "        print('\\n')\n",
    "        #print(sigs)\n",
    "        print('\\n')\n",
    "        #speech2 = ngram_generate(grams2)\n",
    "        speech2 = kBeamsSearch(NGramSearchProblem(N,g2,set(list(MAGIC_WORDS)+sigs)))\n",
    "        sigs = getSigWords(speech2)\n",
    "        print(author2 + ':')\n",
    "        print(speech2)\n",
    "        print('\\n')\n",
    "        #print(sigs)\n",
    "        print('\\n')\n",
    "        speech3 = kBeamsSearch(NGramSearchProblem(N,g3,set(list(MAGIC_WORDS)+sigs)))\n",
    "        sigs = getSigWords(speech3)\n",
    "        print(author3 + ':')\n",
    "        print(speech3)\n",
    "        print('\\n')\n",
    "        #print(sigs)\n",
    "        print('\\n')\n",
    "        i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first ngram density_v2: 2.954440026507621\n",
      "\n",
      "second ngram density_v2: 3.4217966453397892\n",
      "\n",
      "third ngram density_v2: 3.7854438458709243\n",
      "\n",
      "Zhuangzi:\n",
      "The one of these conditions and the other again, and he said, what do you mean?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Augustine:\n",
      "Other things of this life again expose himself to them, the other, so that there are both good and bad.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Plato:\n",
      "Very good. or again, when a good and bad?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Zhuangzi:\n",
      "When good order prevails in the world, and the other again, and he does not know how.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Augustine:\n",
      "Again, if he does not know that they are good, and the other with the other two.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Plato:\n",
      "And does not know the other, if you know of any other art?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Zhuangzi:\n",
      "He does not know how it is that you do not know where they are without the dao.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Augustine:\n",
      " here you see he does not know that it is not, as you say, and to know.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Plato:\n",
      "You will see, if you say that he does not know letters?\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "triple_conv('zhuangzi.txt','augustine_full.txt','plato_full.txt','Zhuangzi', 'Augustine', 'Plato',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def player_conv(text, name):\n",
    "    pname = input(\"Enter your name:\\n\")\n",
    "    grams1 = {}\n",
    "    g1 = initialize_grams(grams1, text)\n",
    "    sigs = []\n",
    "    while(true):\n",
    "        print(\"\\n\" + pname + \": \")\n",
    "        speech = input()\n",
    "        if(speech == \"end\"):\n",
    "            break\n",
    "        #print(speech)\n",
    "        sigs = getSigWords(speech)\n",
    "        speech = kBeamsSearch(NGramSearchProblem(N,g1,set(list(MAGIC_WORDS)+sigs)))\n",
    "        print(\" \\n\" + name + \": \"+ speech + \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name:\n",
      "Sam\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'initialize_grams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2fbd53ccdfcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplayer_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plato_full.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Plato'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-f3cf9ee089c1>\u001b[0m in \u001b[0;36mplayer_conv\u001b[0;34m(text, name)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your name:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgrams1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_grams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrams1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initialize_grams' is not defined"
     ]
    }
   ],
   "source": [
    "player_conv('plato_full.txt', 'Plato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = ['s','a','b','t','n','z','t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-87eead358601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "z.remove([a for a in g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.append('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = ['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
