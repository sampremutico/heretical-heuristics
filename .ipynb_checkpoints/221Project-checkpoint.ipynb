{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://blog.dataiku.com/2016/10/08/machine-learning-markov-chains-generate-clinton-trump-quotes\n",
    "#TODO: get a lot more text for each author, \n",
    "#implement starting a phrase with a <sentence begin> and ending it with a <sentence end>\n",
    "#implement Backoff, \n",
    "#implement word weights (right now the ngram densities are too low for weights to do much) for overall and in-dialogue\n",
    "#graph search\n",
    "#A state is the N words at the end of the sentence, and the list of magic words. A transition between states is the adding of a new word to the end of res. \n",
    "#Ngrams alg defines neighbors\n",
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 3\n",
    "MAX_DIALOGUE_LEN = 15\n",
    "AUTHOR_AUG = \"Augistine\"\n",
    "AUTHOR_ZZ = \"Zhuangzi\"\n",
    "MAGIC_WORDS = set([])#[\"god\",\"man\",\"world\",\"death\",\"heaven\",\"life\",\"time\",\"body\",\"mind\"])\n",
    "grams1 = {}\n",
    "grams2 = {}\n",
    "empty_words = ['.',',',':','i','the','it','for','by','this','they','because','so','is','and','a','with','to','\\'', '\\\"','be','not','no','thus','in','have','as','but','from','on','do','at','or','an','will','my','so','if']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_grams(grams, textfile): #initialize the dicts that store the markov probabilities for N-word chains\n",
    "    f = open(textfile)\n",
    "    s = f.read().replace('(','').replace(')','')\n",
    "    t = nltk.word_tokenize(s)\n",
    "    for i in range(len(t)-(N)):\n",
    "        trigram = tuple(t[x].lower() for x in range(i,i+N))\n",
    "        if trigram in grams.keys():\n",
    "            grams[trigram].add(t[i+N].lower())\n",
    "        else:\n",
    "            grams[trigram] = set([t[i+N].lower()])\n",
    "\n",
    "            \n",
    "def ngram_generate(grams): #generate text from a dict passed in\n",
    "    nwords = 0\n",
    "    start = random.choice([key for key in grams.keys() if key[0].isalpha()])\n",
    "    res = list(start)\n",
    "    while(nwords < 100):\n",
    "        pre = tuple(res[(-1*N):])\n",
    "        nextword = random.choice(list(grams[pre]))\n",
    "        res.append(nextword)\n",
    "        if nextword == '.' or nextword =='?': break\n",
    "        nwords +=1\n",
    "    if nwords ==100: res.append('-')\n",
    "    return \" \".join(res).replace(' .', '.').replace(' ,', ',').replace(' ;',';').replace(' ?', '?').replace(' \\'', '\\'').replace(' !', '!')\n",
    "\n",
    "def solve_density(grams): #On average, how many words are in the dict for each ngram?\n",
    "    total = 0.0\n",
    "    div = 0\n",
    "    for word in grams.keys():\n",
    "        if(len(grams[word])>1):\n",
    "            total += len(grams[word])\n",
    "            div +=1\n",
    "    return total/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize_grams(grams1, 'augustine_full.txt')\n",
    "#initialize_grams(grams1, 'zhuangzi.txt')\n",
    "#solve_density(grams1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NGramSearchProblem(object):\n",
    "    def __init__(self, N, grams, magic_words):\n",
    "        self.N = N\n",
    "        self.grams = grams\n",
    "        self.magic_words = magic_words\n",
    "        self.startActions = None\n",
    "\n",
    "    # Trivially return 100 if word is magic word, 1 otherwise\n",
    "    def ngram_cost(self,state):\n",
    "        if state[-1] in MAGIC_WORDS:\n",
    "            return 2\n",
    "        return 1\n",
    "    \n",
    "    def ngram_generate_next_words(self, curr_gram):\n",
    "        pre = tuple(curr_gram[(-1*N):])\n",
    "        return list(self.grams[pre])\n",
    "    \n",
    "    def startState(self):\n",
    "        valid_start_keys = [key for key in self.grams.keys() if key[0].isalpha()]\n",
    "        start = random.choice(valid_start_keys) #TODO: initialize first n_gram \n",
    "        self.startActions = list(start)\n",
    "        return list(start)\n",
    "\n",
    "    def isEnd(self, state):\n",
    "        return len(state) >= MAX_DIALOGUE_LEN or state[-1][-1] == \".\" or state[-1][-1] == \"?\" #max blurb length or last word ends in period\n",
    "    \n",
    "    def succAndCost(self, state):\n",
    "        result = []\n",
    "        possible_next_words = self.ngram_generate_next_words(state)\n",
    "        for next_word in possible_next_words:\n",
    "            next_state = state[:]+[next_word]\n",
    "            result.append((next_word, next_state, self.ngram_cost(next_state)))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backtrackingSearch(problem):\n",
    "    bestTotalCost = [float('-inf')]\n",
    "    bestHistory = [None]\n",
    "    def recurse(state,curr_history,curr_cost):\n",
    "        if problem.isEnd(state):\n",
    "            if curr_cost > bestTotalCost[0]:\n",
    "                bestTotalCost[0], bestHistory[0] = curr_cost, curr_history \n",
    "            return\n",
    "        for action, next_state, cost in problem.succAndCost(state):\n",
    "            recurse(next_state, curr_history+[action], curr_cost+cost)\n",
    "    \n",
    "    recurse(problem.startState(),[],0)\n",
    "    bestHistory = \" \".join(problem.startActions).replace(' .', '.').replace(' ,', ',').replace(' ;',';').replace(' ?', '?').replace(' \\'', '\\'').replace(' !', '!')+\" \"+\" \".join(bestHistory[0]).replace(' .', '.').replace(' ,', ',').replace(' ;',';').replace(' ?', '?').replace(' \\'', '\\'').replace(' !', '!')\n",
    "   # print(\"<-----------Best History--------->\")\n",
    "    #print(bestHistory)return \n",
    "    #print(\"<--------------Score------------->\")\n",
    "    #print(bestTotalCost[0])\n",
    "    return bestHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#blurb = backtrackingSearch(NGramSearchProblem(N,grams1,MAGIC_WORDS)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convo(text1, text2, author1, author2):\n",
    "    initialize_grams(grams1, text1)\n",
    "    initialize_grams(grams2, text2)\n",
    "    print('first ngram density: '+ str(solve_density(grams1))+ '\\n')\n",
    "    print('second ngram density: '+ str(solve_density(grams2))+ '\\n')\n",
    "    sigs = []\n",
    "    for i in range(5):\n",
    "        print(author1 + ':')\n",
    "        speech1 = ngram_generate(grams1)\n",
    "        #speech1 = backtrackingSearch(NGramSearchProblem(N,grams1,set(list(MAGIC_WORDS)+sigs)))\n",
    "        sigs = getSigWords(speech1)\n",
    "        print(speech1)\n",
    "        print('\\n')\n",
    "        speech2 = ngram_generate(grams2)\n",
    "        #speech2 = backtrackingSearch(NGramSearchProblem(N,grams2,set(list(MAGIC_WORDS)+sigs)))\n",
    "        sigs = getSigWords(speech2)\n",
    "        print(author2 + ':')\n",
    "        print(speech2)\n",
    "        print('\\n')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first ngram density: 3.4217966453397892\n",
      "\n",
      "second ngram density: 2.5869829683698295\n",
      "\n",
      "Augustine:\n",
      "inhabit the air, but by abiding in god.\n",
      "\n",
      "\n",
      "Zhuangzi:\n",
      "let him hear your notes; if he will not live; -- not for ten days more! i saw something strange about him - i saw the ashes of his life.\n",
      "\n",
      "\n",
      "Augustine:\n",
      "her sound doctrine maintained any tenet which should confine thee, the one good, the other after death.\n",
      "\n",
      "\n",
      "Zhuangzi:\n",
      "there be speech about them?\n",
      "\n",
      "\n",
      "Augustine:\n",
      "troy. for their virtue, â€”if, i say not he is foolish, but mad.\n",
      "\n",
      "\n",
      "Zhuangzi:\n",
      "and when men praise yao and condemn jie, it would be so as well with the stupid and unthinking.\n",
      "\n",
      "\n",
      "Augustine:\n",
      "possibly be eternal if god should so will it?\n",
      "\n",
      "\n",
      "Zhuangzi:\n",
      "and maintained a perfect government within the four seas; that by the concentration of his spirit-like powers he could save men from disease and pestilence, and secure every year a plentiful harvest.\n",
      "\n",
      "\n",
      "Augustine:\n",
      "to go, there appeared unto me the chaste dignity of continency, serene, yet not on that account escape the laws of the twelve tables are prohibited from injuring the good name of the leading men and the common citizens, when the body is subjected to the roman power, and glory, they achieved many great things; and what their ritual prescribed as acceptable to the deities, and either feigned concerning those whom they conquered.\n",
      "\n",
      "\n",
      "Zhuangzi:\n",
      "are hastening my death, and that she was no longer like themselves.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "convo('augustine_full.txt', 'zhuangzi.txt', 'Augustine', 'Zhuangzi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSigWords(str):\n",
    "    s = set(nltk.word_tokenize(str))\n",
    "    for w in empty_words:\n",
    "        if w in s: s.remove(w)\n",
    "    return list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = 'I love. to ball.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'affirming', 'end', 'those', 'without'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSigWords('affirming, and without end to those affirming, and without end to those affirming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ball', 'NN'), ('run', 'VB'), ('dog', 'NN'), ('jump', 'NN')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = ['s','a','b','t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ['s','a','b','t','n','z','t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-87eead358601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "z.remove([a for a in g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = ['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
